library(tidyr)
library(ggplot2)
library(pROC)
library(ROCR)
# Citim setul de date
potabilitate <- read_csv("dataset.csv")
potabilitate <- na.omit(potabilitate)
potabilitate <- na.omit(potabilitate)
# Impartim setul de date in setul de antrenare si setul de testare
set.seed(123)
split <- initial_split(potabilitate, prop = 0.7, strata = "Target")
train <- training(split)
test <- testing(split)
# Definim variabilele de intrare si de iesire pentru model
features <-setdiff(names(train), "Target")
x <-train[,features]
y <-train$Target
fitControl <- trainControl(method = 'cv', number = 5)
model <- train(
x=x,
y=y,
method="glm",
family="binomial",
trControl = fitControl
)
conf1<-confusionMatrix(factor(ifelse(predictions > 0.5, 1, 0), levels = c(0,1)), factor(test$Target, levels = c(0, 1)))
conf1
model <- train(
x=x,
y=y,
method="glm",
family="binomial",
trControl = fitControl
)
predictions <- predict(model, newdata = test)
conf1<-confusionMatrix(factor(ifelse(predictions > 0.5, 1, 0), levels = c(0,1)), factor(test$Target, levels = c(0, 1)))
conf1
# Model 2: Subset de variabile
model2 <- glm(Target ~ Chloride + Turbidity + Copper, family = binomial, data = train)
pred2 <- predict(model2, newdata = test, type = "response")
conf2 <-confusionMatrix(factor(ifelse(pred2 > 0.5, 1, 0), levels = c(0,1)), factor(test$Target, levels = c(0, 1)))
# Model 3: O singură variabilă
model3 <- glm(Target ~ Copper, family = binomial, data = train)
pred3 <- predict(model3, newdata = test, type = "response")
conf3 <-confusionMatrix(factor(ifelse(pred3 > 0.5, 1, 0), levels = c(0,1)), factor(test$Target, levels = c(0, 1)))
conf2
metrics <- data.frame(
model = c("Model 1", "Model 2", "Model 3"),
accuracy = c(conf1$overall["Accuracy"], conf2$overall["Accuracy"], conf3$overall["Accuracy"]),
sensitivity = c(conf1$byClass["Sensitivity"], conf2$byClass["Sensitivity"], conf3$byClass["Sensitivity"]),
specificity = c(conf1$byClass["Specificity"], conf2$byClass["Specificity"], conf3$byClass["Specificity"])
)
# Format metrics
metrics$accuracy <- sprintf("%.2f%%", metrics$accuracy * 100)
metrics$sensitivity <- sprintf("%.2f%%", metrics$sensitivity * 100)
metrics$specificity <- sprintf("%.2f%%", metrics$specificity * 100)
# Reorder rows
metrics <- metrics %>% arrange(model)
# Print results
metrics
# Generează obiectul de performanță ROC
roc_obj <- roc(test$Target, pred3)
# Desenează curba ROC
plot(roc_obj, main = "Curba ROC pentru Model 3")
# Calculează aria de sub curba ROC
auc(roc_obj)
predictions <- na.omit(predictions)
ggplot(data = potabilitate, aes(x = Target, y = pH)) +
geom_boxplot(fill = "cornflowerblue", color = "black") +
labs(x = "Target", y = "ph", title = "Distribuția pH-ului în funcție de Target")
library(ggplot2)
df_long <- gather(df, metric, value, -model)
library(tidyverse)
library(rsample)
library(caret)
library(tidyr)
library(ggplot2)
library(e1071)
library(pROC)
library(ROCR)
# Citim setul de date
potabilitate <- read_csv("dataset.csv")
# Eliminam valorile incomplete
potabilitate <- na.omit(potabilitate)
potabilitate$Target <- ifelse(potabilitate$Target == 1, "Da", "Nu")
# Realizam cross-validation cu 10 fold-uri
set.seed(123)
folds <- vfold_cv(potabilitate, v = 10, strata = "Target")
# Definim variabilele de intrare si de iesire pentru model
features <- setdiff(names(potabilitate), "Target")
# Definim controlul pentru modelul Naive Bayes
ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3,
summaryFunction = twoClassSummary, classProbs = TRUE)
# Cream modelul Naive Bayes cu functia train
nb_model <- train(potabilitate[, features], potabilitate$Target,
method = "naive_bayes", trControl = ctrl, metric = "ROC")
library(tidyverse)
library(rsample)
library(caret)
library(tidyr)
library(ggplot2)
library(e1071)
library(pROC)
library(ROCR)
# Citim setul de date
potabilitate <- read_csv("dataset.csv")
# Eliminam valorile incomplete
potabilitate <- na.omit(potabilitate)
potabilitate$Target <- ifelse(potabilitate$Target == 1, "Da", "Nu")
# Realizam cross-validation cu 10 fold-uri
set.seed(123)
folds <- vfold_cv(potabilitate, v = 10, strata = "Target")
# Definim variabilele de intrare si de iesire pentru model
features <- setdiff(names(potabilitate), "Target")
ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3,
summaryFunction = twoClassSummary, classProbs = TRUE)
nb_model <- train(potabilitate[, features], potabilitate$Target,
method = "naive_bayes", trControl = ctrl, metric = "ROC")
potabilitate <- potabilitate %>% sample_n(10000)
# Realizam cross-validation cu 10 fold-uri
set.seed(123)
folds <- vfold_cv(potabilitate, v = 10, strata = "Target")
# Definim variabilele de intrare si de iesire pentru model
features <- setdiff(names(potabilitate), "Target")
# Definim controlul pentru modelul Naive Bayes
ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3,
summaryFunction = twoClassSummary, classProbs = TRUE)
# Cream modelul Naive Bayes cu functia train
nb_model <- train(potabilitate[, features], potabilitate$Target,
method = "naive_bayes", trControl = ctrl, metric = "ROC")
# Afisam informatii despre model
nb_model
predictions <- predict(nb_model, newdata = test, type = "prob")
# Separă setul de date în set de antrenament și testare
set.seed(123)
split <- initial_split(potabilitate, prop = 0.7, strata = "Target")
train <- training(split)
test <- testing(split)
test <- testing(split)
folds <- vfold_cv(potabilitate, v = 10, strata = "Target")
# Definim variabilele de intrare si de iesire pentru model
features <- setdiff(names(potabilitate), "Target")
# Definim controlul pentru modelul Naive Bayes
ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3,
summaryFunction = twoClassSummary, classProbs = TRUE)
# Cream modelul Naive Bayes cu functia train
nb_model <- train(potabilitate[, features], potabilitate$Target,
method = "naive_bayes", trControl = ctrl, metric = "ROC")
# Afisam informatii despre model
nb_model
predictions <- predict(nb_model, newdata = test, type = "prob")
# Generează obiectul de performanță ROC
prob_pos_class <- predictions[, 1]
# Desenează curba ROC
roc_curve <- roc(test$Target, prob_pos_class)
# Afisam curba ROC
ggroc(roc_curve) + labs(title = "Curba ROC - Naive Bayes")
auc(roc_curve)
search_grid <- expand.grid(
usekernel = c(TRUE, FALSE),
fL = 0.5,
adjust = seq(0, 5, by =1))
search_grid
# Definim controlul pentru modelul Naive Bayes
ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3,
summaryFunction = twoClassSummary, classProbs = TRUE)
# Definim grid-ul de hiperparametri
search_grid <- expand.grid(
usekernel = c(TRUE, FALSE),
fL = 0.5,
adjust = seq(0, 5, by =1)
)
# Antrenăm un nou model folosind search_grid
nb_model_new <- train(
x = train[, features],
y = train$Target,
method = "naive_bayes",
tuneGrid = search_grid,
trControl = ctrl,
metric = "ROC"
)
# Definim controlul pentru modelul Naive Bayes
ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3,
summaryFunction = twoClassSummary, classProbs = TRUE)
# Definim grid-ul de hiperparametri
search_grid <- expand.grid(
laplace = seq(0, 5, by = 1),
usekernel = c(TRUE, FALSE),
adjust = seq(0, 5, by = 1)
)
# Selectăm rândul corespunzător valorilor dorite
selected_row <- search_grid[search_grid$fL == 0.5 & search_grid$usekernel == TRUE & search_grid$adjust == 4, ]
# Antrenăm un nou model folosind valorile selectate
nb_model_new <- train(
x = train[, features],
y = train$Target,
method = "naive_bayes",
tuneGrid = selected_row,
trControl = ctrl,
metric = "ROC"
)
# Set the random seed
set.seed(123)
# Define control for Naive Bayes model
ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3,
summaryFunction = twoClassSummary, classProbs = TRUE)
# Define the search grid
search_grid <- expand.grid(
laplace = seq(0, 5, by = 1),
usekernel = c(TRUE, FALSE),
adjust = seq(0, 5, by = 1)
)
# Select the desired values from the search grid
selected_row <- search_grid[search_grid$laplace == 0.5 & search_grid$usekernel == TRUE & search_grid$adjust == 4, ]
# Train a new model using the selected values
nb_model_new <- train(
x = train[, features],
y = train$Target,
method = "naive_bayes",
tuneGrid = selected_row,
trControl = ctrl,
metric = "ROC"
)
library(rpart)
library(rpart.plot)
install.packages("rpart.plot")
library(rpart.plot)
# Construim modelul de arbori de decizie
tree_model <- rpart(Target ~ ., data = train, method = "class")
# Vizualizăm arborele de decizie
rpart.plot(tree_model, box.palette = "RdBu", shadow.col = "gray")
# Efectuăm predicții pe setul de testare
predictions <- predict(tree_model, newdata = test, type = "class")
# Calculăm acuratețea modelului
accuracy <- sum(predictions == test$Target) / length(predictions)
accuracy
# Efectuăm predicții pe setul de testare
predictions <- predict(tree_model, newdata = test, type = "class")
# Afișăm matricea de confuzie
print(confusion)
# Efectuați predicții pe setul de testare
probabilities <- predict(tree_model, newdata = test, type = "prob")
# Extrageți probabilitatea clasei pozitive
prob_pos_class <- probabilities[, "Da"]
# Calculați obiectul de performanță ROC
roc_obj <- roc(test$Target, prob_pos_class)
# Desenați curba ROC
plot(roc_obj, main = "Curba ROC - Model de Arbori de Decizie",
xlab = "Rata de Fals Pozitive", ylab = "Rata de Adevărate Pozitive")
# Calculați AUC
auc_score <- auc(roc_obj)
# Afișați AUC
print(auc_score)
potabilitate <- potabilitate %>% sample_n(10000)
# Impartim setul de date in setul de antrenare si setul de testare
set.seed(123)
split <- initial_split(potabilitate, prop = 0.7, strata = "Target")
train <- training(split)
test <- testing(split)
# Definim variabilele de intrare si de iesire pentru model
features <-setdiff(names(train), "Target")
x <-train[,features]
y <-train$Target
fitControl <- trainControl(method = 'cv', number = 5)
model <- train(
x=x,
y=y,
method="glm",
family="binomial",
trControl = fitControl
)
predictions <- predict(model, newdata = test)
conf1<-confusionMatrix(factor(ifelse(predictions > 0.5, 1, 0), levels = c(0,1)), factor(test$Target, levels = c(0, 1)))
# Model 2: Subset de variabile
model2 <- glm(Target ~ Chloride + Turbidity + Copper, family = binomial, data = train)
pred2 <- predict(model2, newdata = test, type = "response")
conf2 <-confusionMatrix(factor(ifelse(pred2 > 0.5, 1, 0), levels = c(0,1)), factor(test$Target, levels = c(0, 1)))
# Model 2: Subset de variabile
model2 <- glm(Target ~ Chloride + Turbidity + Copper, family = binomial, data = train)
pred2 <- predict(model2, newdata = test, type = "response")
conf2 <-confusionMatrix(factor(ifelse(pred2 > 0.5, 1, 0), levels = c(0,1)), factor(test$Target, levels = c(0, 1)))
library(tidyverse)
library(rsample)
library(caret)
library(tidyr)
library(ggplot2)
library(e1071)
library(rpart)
library(rpart.plot)
library(pROC)
library(ROCR)
# Citim setul de date
potabilitate <- read_csv("dataset.csv")
potabilitate <- na.omit(potabilitate)
potabilitate <- potabilitate %>% sample_n(10000)
# Impartim setul de date in setul de antrenare si setul de testare
set.seed(123)
split <- initial_split(potabilitate, prop = 0.7, strata = "Target")
train <- training(split)
test <- testing(split)
# Definim variabilele de intrare si de iesire pentru model
features <-setdiff(names(train), "Target")
x <-train[,features]
y <-train$Target
fitControl <- trainControl(method = 'cv', number = 5)
model <- train(
x=x,
y=y,
method="glm",
family="binomial",
trControl = fitControl
)
predictions <- predict(model, newdata = test)
conf1<-confusionMatrix(factor(ifelse(predictions > 0.5, 1, 0), levels = c(0,1)), factor(test$Target, levels = c(0, 1)))
# Model 2: Subset de variabile
model2 <- glm(Target ~ Chloride + Turbidity + Copper, family = binomial, data = train)
pred2 <- predict(model2, newdata = test, type = "response")
conf2 <-confusionMatrix(factor(ifelse(pred2 > 0.5, 1, 0), levels = c(0,1)), factor(test$Target, levels = c(0, 1)))
# Model 3: O singură variabilă
model3 <- glm(Target ~ Copper, family = binomial, data = train)
pred3 <- predict(model3, newdata = test, type = "response")
conf3 <-confusionMatrix(factor(ifelse(pred3 > 0.5, 1, 0), levels = c(0,1)), factor(test$Target, levels = c(0, 1)))
metrics <- data.frame(
model = c("Model 1", "Model 2", "Model 3"),
accuracy = c(conf1$overall["Accuracy"], conf2$overall["Accuracy"], conf3$overall["Accuracy"]),
sensitivity = c(conf1$byClass["Sensitivity"], conf2$byClass["Sensitivity"], conf3$byClass["Sensitivity"]),
specificity = c(conf1$byClass["Specificity"], conf2$byClass["Specificity"], conf3$byClass["Specificity"])
)
# Format metrics
metrics$accuracy <- sprintf("%.2f%%", metrics$accuracy * 100)
metrics$sensitivity <- sprintf("%.2f%%", metrics$sensitivity * 100)
metrics$specificity <- sprintf("%.2f%%", metrics$specificity * 100)
# Reorder rows
metrics <- metrics %>% arrange(model)
# Print results
metrics
# Citim setul de date
potabilitate <- read_csv("dataset.csv")
potabilitate <- na.omit(potabilitate)
potabilitate <- potabilitate %>% sample_n(10000)
# Impartim setul de date in setul de antrenare si setul de testare
set.seed(123)
split <- initial_split(potabilitate, prop = 0.7, strata = "Target")
train <- training(split)
test <- testing(split)
# Definim variabilele de intrare si de iesire pentru model
features <-setdiff(names(train), "Target")
# Construim modelul de arbori de decizie
tree_model <- rpart(Target ~ ., data = train, method = "class")
# Vizualizăm arborele de decizie
rpart.plot(tree_model, box.palette = "RdBu", shadow.col = "gray")
# Efectuăm predicții pe setul de testare
predictions <- predict(tree_model, newdata = test, type = "class")
# Calculăm acuratețea modelului
accuracy <- sum(predictions == test$Target) / length(predictions)
accuracy
# Efectuați predicții pe setul de testare
probabilities <- predict(tree_model, newdata = test, type = "prob")
# Extrageți probabilitatea clasei pozitive
prob_pos_class <- probabilities[, "Da"]
potabilitate$Target <- ifelse(potabilitate$Target == 1, "Da", "Nu")
library(tidyverse)
library(rsample)
library(caret)
library(tidyr)
library(ggplot2)
library(e1071)
library(rpart)
library(rpart.plot)
library(pROC)
library(ROCR)
# Efectuați predicții pe setul de testare
probabilities <- predict(tree_model, newdata = test, type = "prob")
# Extrageți probabilitatea clasei pozitive
prob_pos_class <- probabilities[, "Da"]
# Calculați obiectul de performanță ROC
roc_obj <- roc(test$Target, prob_pos_class)
# Desenați curba ROC
plot(roc_obj, main = "Curba ROC - Model de Arbori de Decizie",
xlab = "Rata de Fals Pozitive", ylab = "Rata de Adevărate Pozitive")
# Afișați AUC
print(auc_score)
library(tidyverse)
library(rsample)
library(caret)
library(tidyr)
library(ggplot2)
library(e1071)
library(rpart)
library(rpart.plot)
library(pROC)
library(ROCR)
# Citim setul de date
potabilitate <- read_csv("dataset.csv")
potabilitate <- na.omit(potabilitate)
potabilitate <- potabilitate %>% sample_n(10000)
# Impartim setul de date in setul de antrenare si setul de testare
set.seed(123)
split <- initial_split(potabilitate, prop = 0.7, strata = "Target")
train <- training(split)
test <- testing(split)
# Definim variabilele de intrare si de iesire pentru model
features <-setdiff(names(train), "Target")
x <-train[,features]
y <-train$Target
fitControl <- trainControl(method = 'cv', number = 5)
model <- train(
x=x,
y=y,
method="glm",
family="binomial",
trControl = fitControl
)
predictions <- predict(model, newdata = test)
conf1<-confusionMatrix(factor(ifelse(predictions > 0.5, 1, 0), levels = c(0,1)), factor(test$Target, levels = c(0, 1)))
# Model 2: Subset de variabile
model2 <- glm(Target ~ Chloride + Turbidity + Copper, family = binomial, data = train)
pred2 <- predict(model2, newdata = test, type = "response")
conf2 <-confusionMatrix(factor(ifelse(pred2 > 0.5, 1, 0), levels = c(0,1)), factor(test$Target, levels = c(0, 1)))
# Model 3: O singură variabilă
model3 <- glm(Target ~ Copper, family = binomial, data = train)
pred3 <- predict(model3, newdata = test, type = "response")
conf3 <-confusionMatrix(factor(ifelse(pred3 > 0.5, 1, 0), levels = c(0,1)), factor(test$Target, levels = c(0, 1)))
metrics <- data.frame(
model = c("Model 1", "Model 2", "Model 3"),
accuracy = c(conf1$overall["Accuracy"], conf2$overall["Accuracy"], conf3$overall["Accuracy"]),
sensitivity = c(conf1$byClass["Sensitivity"], conf2$byClass["Sensitivity"], conf3$byClass["Sensitivity"]),
specificity = c(conf1$byClass["Specificity"], conf2$byClass["Specificity"], conf3$byClass["Specificity"])
)
# Format metrics
metrics$accuracy <- sprintf("%.2f%%", metrics$accuracy * 100)
metrics$sensitivity <- sprintf("%.2f%%", metrics$sensitivity * 100)
metrics$specificity <- sprintf("%.2f%%", metrics$specificity * 100)
# Reorder rows
metrics <- metrics %>% arrange(model)
# Print results
metrics
potabilitate$Target <- ifelse(potabilitate$Target == 1, "Da", "Nu")
# Separă setul de date în set de antrenament și testare
set.seed(123)
split <- initial_split(potabilitate, prop = 0.7, strata = "Target")
train <- training(split)
test <- testing(split)
folds <- vfold_cv(potabilitate, v = 10, strata = "Target")
# Definim variabilele de intrare si de iesire pentru model
features <- setdiff(names(potabilitate), "Target")
# Definim controlul pentru modelul Naive Bayes
ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3,
summaryFunction = twoClassSummary, classProbs = TRUE)
# Cream modelul Naive Bayes cu functia train
nb_model <- train(potabilitate[, features], potabilitate$Target,
method = "naive_bayes", trControl = ctrl, metric = "ROC")
# Afisam informatii despre model
nb_model
predictions <- predict(nb_model, newdata = test, type = "prob")
# Generează obiectul de performanță ROC
prob_pos_class <- predictions[, 1]
# Desenează curba ROC
roc_curve <- roc(test$Target, prob_pos_class)
# Afisam curba ROC
ggroc(roc_curve) + labs(title = "Curba ROC - Naive Bayes")
auc(roc_curve)
roc_obj1 <- roc(test$Target, predictions)
roc_obj2 <- roc(test$Target, pred2)
roc_obj3 <- roc(test$Target, pred3)
roc_obj4 <- roc(test$Target, prob_pos_class)
# Create an empty plot
plot(0, 0, type = "n", xlim = c(0, 1), ylim = c(0, 1),
xlab = "False Positive Rate", ylab = "True Positive Rate",
main = "ROC Curves for Models")
# Add ROC curves one by one
lines(roc_obj1, col = "red")
lines(roc_obj2, col = "blue")
lines(roc_obj3, col = "green")
lines(roc_obj4, col = "black")
# Add a legend
legend("bottomright", legend = c("Model 1", "Model 2", "Model 3","Naive Bayes Model"),
col = c("red", "blue", "green","black"), lty = 1)
# Add a legend
legend("bottomright", legend = c("Model 1", "Model 2", "Model 3","Naive Bayes Model"),
col = c("red", "blue", "green","black"),lty=1)
# Separă setul de date în set de antrenament și testare
set.seed(123)
split <- initial_split(potabilitate, prop = 0.7, strata = "Target")
train <- training(split)
test <- testing(split)
# Construim modelul de arbori de decizie
tree_model <- rpart(Target ~ ., data = train, method = "class")
# Vizualizăm arborele de decizie
rpart.plot(tree_model, box.palette = "RdBu", shadow.col = "gray")
# Efectuăm predicții pe setul de testare
predictions <- predict(tree_model, newdata = test, type = "class")
# Calculăm acuratețea modelului
accuracy <- sum(predictions == test$Target) / length(predictions)
accuracy
# Efectuăm predicții pe setul de testare
predictions <- predict(tree_model, newdata = test, type = "class")
# Afișăm matricea de confuzie
print(confusion)
# Efectuați predicții pe setul de testare
probabilities <- predict(tree_model, newdata = test, type = "prob")
# Extrageți probabilitatea clasei pozitive
prob_pos_class <- probabilities[, "Da"]
# Calculați obiectul de performanță ROC
roc_obj <- roc(test$Target, prob_pos_class)
# Desenați curba ROC
plot(roc_obj, main = "Curba ROC - Model de Arbori de Decizie",
xlab = "Rata de Fals Pozitive", ylab = "Rata de Adevărate Pozitive")
# Calculați AUC
auc_score <- auc(roc_obj)
# Afișați AUC
print(auc_score)
